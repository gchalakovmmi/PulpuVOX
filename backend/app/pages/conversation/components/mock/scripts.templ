package mock

import ()

templ Scripts() {
    <script src="https://cdn.jsdelivr.net/npm/lamejs@1.2.0/lame.min.js"></script>
    <script>
        // Variables to manage recording state
        let mediaRecorder;
        let audioChunks = [];
        let stream;
        let conversationHistory = [];
        let isFirstTurn = true;
        let isRecording = false;
        let userName = "You"; // Default value
        let recordingTimeout;

        // Get references to UI elements
        const startButton = document.getElementById('startButton');
        const endButton = document.getElementById('endButton');
        const endConversationButton = document.getElementById('endConversationButton');
        const statusText = document.getElementById('status');
        const messagesContainer = document.getElementById('messages-container');

        // Hello sound URL
        const helloSoundUrl = "/static/audio/hello.mp3";

        // Function to update the message display
        function updateMessageDisplay() {
            messagesContainer.innerHTML = '';
            
            conversationHistory.forEach(turn => {
                const messageDiv = document.createElement('div');
                messageDiv.className = turn.role === 'user' ? 'message user-message' : 'message assistant-message';
                
                const roleSpan = document.createElement('span');
                roleSpan.className = 'message-role';
                
                if (turn.role === 'user') {
                    roleSpan.textContent = (turn.user_name || userName) + ': ';
                } else if (turn.role === 'assistant') {
                    roleSpan.textContent = 'Voxy: ';
                } else {
                    roleSpan.textContent = turn.role + ': ';
                }
                
                const contentSpan = document.createElement('span');
                contentSpan.className = 'message-content';
                contentSpan.textContent = turn.content;
                
                messageDiv.appendChild(roleSpan);
                messageDiv.appendChild(contentSpan);
                
                // Add suggestion if available
                if (turn.suggestion !== undefined && turn.suggestion !== '') {
                    // Normalize for comparison
                    const normalizedSuggestion = normalizeTextForComparison(turn.suggestion);
                    const normalizedContent = normalizeTextForComparison(turn.content);
                    
                    if (normalizedSuggestion === normalizedContent || normalizedSuggestion === '') {
                        // Show positive feedback for correct sentences
                        const positiveDiv = document.createElement('div');
                        positiveDiv.className = 'positive-feedback';
                        positiveDiv.innerHTML = 'âœ“ Good job! Your sentence is correct.';
                        messageDiv.appendChild(positiveDiv);
                    } else {
                        // Show suggestion for incorrect sentences
                        const suggestionDiv = document.createElement('div');
                        suggestionDiv.className = 'suggestion';
                        suggestionDiv.innerHTML = '<strong>Suggestion:</strong> ' + turn.suggestion;
                        messageDiv.appendChild(suggestionDiv);
                    }
                } else if (turn.role === 'user' && turn.isProcessing) {
                    // Show processing indicator for user messages that are still being processed
                    const processingDiv = document.createElement('div');
                    processingDiv.className = 'processing';
                    processingDiv.innerHTML = 'Processing...';
                    messageDiv.appendChild(processingDiv);
                }
                
                messagesContainer.appendChild(messageDiv);
            });
            
            // Scroll to bottom to show latest message
            messagesContainer.scrollTop = messagesContainer.scrollHeight;
        }

        // Function to stop recording
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                // Update UI
                endButton.disabled = true;
                // Clear the timeout if recording is stopped manually
                if (recordingTimeout) {
                    clearTimeout(recordingTimeout);
                    recordingTimeout = null;
                }
            }
        }

        // Function to start recording automatically
        function startRecordingAutomatically() {
            // For subsequent turns, start recording immediately
            startRecordingProcess();
        }

        // Function to handle the recording process
        async function startRecordingProcess() {
            try {
                if (isRecording) return; // Prevent multiple recordings
                
                isRecording = true;
                startButton.disabled = true;
                statusText.innerHTML = '<span class="indicator"></span> Starting recording...';
                
                // Stop any existing stream
                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                }
                
                // Request access to the microphone
                stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 44100,
                        sampleSize: 16
                    }
                });
                
                // Create a media recorder instance
                mediaRecorder = new MediaRecorder(stream);
                
                // Reset audio chunks
                audioChunks = [];
                
                // Event handler for when data is available
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                // Event handler for when recording stops
                mediaRecorder.onstop = () => {
                    statusText.innerHTML = '<span class="indicator"></span> Processing...';
                    // Create a blob from the audio chunks
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    // Convert to MP3
                    convertToMp3(audioBlob);
                    isRecording = false;
                };
                
                // Start recording
                mediaRecorder.start();
                statusText.innerHTML = '<span class="indicator pulse"></span> Recording... Speak now';
                
                // Update UI
                endButton.disabled = false;
                
                // Set a timeout to automatically stop recording after 30 seconds
                recordingTimeout = setTimeout(() => {
                    if (isRecording) {
                        statusText.innerHTML = '<span class="indicator"></span> Time limit reached, processing...';
                        stopRecording();
                    }
                }, 30000); // 30 seconds
                
            } catch (error) {
                console.error("Error:", error);
                statusText.textContent = "Error: " + error.message;
                startButton.disabled = false;
                isRecording = false;
                // Clear the timeout if there was an error
                if (recordingTimeout) {
                    clearTimeout(recordingTimeout);
                    recordingTimeout = null;
                }
            }
        }

        // Event handler for the start button
        startButton.addEventListener('click', async () => {
            try {
                startButton.disabled = true;
                statusText.innerHTML = '<span class="indicator"></span> Playing hello sound...';

                // If it's the first turn, add the hello message immediately
                if (isFirstTurn) {
                    const helloMessage = {
                        role: 'assistant',
                        content: "Hello! What would you like to talk about today?"
                    };
                    conversationHistory.push(helloMessage);
                    updateMessageDisplay();
                    isFirstTurn = false;
                }

                // Play the hello sound
                const helloSound = new Audio(helloSoundUrl);
                helloSound.onended = async () => {
                    await startRecordingProcess();
                };
                helloSound.onerror = (error) => {
                    console.error("Error playing hello sound:", error);
                    statusText.textContent = "Error playing hello sound";
                    startButton.disabled = false;
                };
                helloSound.play().catch(error => {
                    console.error("Failed to play hello sound:", error);
                    statusText.textContent = "Failed to play hello sound";
                    startButton.disabled = false;
                });
            } catch (error) {
                console.error("Error:", error);
                statusText.textContent = "Error: " + error.message;
                startButton.disabled = false;
            }
        });

        // Event handler for the end button
        endButton.addEventListener('click', () => {
            stopRecording();
        });

        // Event handler for the end conversation button
        endConversationButton.addEventListener('click', endConversation);

        function endConversation() {
            // Save conversation to sessionStorage for the analysis page
            sessionStorage.setItem('currentConversation', JSON.stringify(conversationHistory));
            
            fetch('/api/conversation/end', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ history: conversationHistory })
            })
            .then(response => {
                if (!response.ok) {
                    throw new Error('Failed to end conversation');
                }
                return response.json();
            })
            .then(data => {
                window.location.href = data.redirect;
            })
            .catch(error => {
                console.error('Error ending conversation:', error);
                statusText.textContent = "Error ending conversation: " + error.message;
            });
        }

        // Function to convert audio to MP3 using lamejs
        function convertToMp3(blob) {
            // Create a file reader to read the blob
            const reader = new FileReader();
            reader.onload = function() {
                // Create audio context to decode audio
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                audioContext.decodeAudioData(reader.result, function(buffer) {
                    // Get the PCM data from the buffer
                    const pcmData = buffer.getChannelData(0);
                    const sampleRate = buffer.sampleRate;
                    // Initialize the MP3 encoder
                    const mp3Encoder = new lamejs.Mp3Encoder(1, sampleRate, 128);
                    // Convert float32 to int16
                    const samples = new Int16Array(pcmData.length);
                    for (let i = 0; i < pcmData.length; i++) {
                        samples[i] = pcmData[i] * 32767;
                    }
                    // Encode the PCM data to MP3
                    const mp3Data = [];
                    const sampleBlockSize = 1152;
                    for (let i = 0; i < samples.length; i += sampleBlockSize) {
                        const chunk = samples.subarray(i, i + sampleBlockSize);
                        const mp3Buffer = mp3Encoder.encodeBuffer(chunk);
                        if (mp3Buffer.length > 0) {
                            mp3Data.push(mp3Buffer);
                        }
                    }
                    // Finalize the encoding
                    const finalBuffer = mp3Encoder.flush();
                    if (finalBuffer.length > 0) {
                        mp3Data.push(finalBuffer);
                    }
                    // Combine all MP3 data
                    const combined = new Uint8Array(mp3Data.reduce((acc, val) => {
                        const newArray = new Uint8Array(acc.length + val.length);
                        newArray.set(acc);
                        newArray.set(val, acc.length);
                        return newArray;
                    }, new Uint8Array()));
                    // Create a blob from the MP3 data
                    const mp3Blob = new Blob([combined], { type: 'audio/mp3' });
                    // Send to server for transcription and TTS
                    sendToServer(mp3Blob);
                }, function(error) {
                    console.error("Error decoding audio:", error);
                    statusText.textContent = "Error processing audio";
                    startButton.disabled = false;
                });
            };
            reader.onerror = function(error) {
                console.error("Error reading blob:", error);
                statusText.textContent = "Error processing recording";
                startButton.disabled = false;
            };
            // Read the blob as array buffer
            reader.readAsArrayBuffer(blob);
        }

        // Function to send MP3 to server
        function sendToServer(mp3Blob) {
            const formData = new FormData();
            formData.append('audio', mp3Blob, 'recording.mp3');
            formData.append('history', JSON.stringify(conversationHistory));

            // Add a temporary user message with "Processing..." indicator
            conversationHistory.push({
                role: 'user',
                content: 'Processing...',
                isProcessing: true
            });
            updateMessageDisplay();

            fetch('/api/conversation/turn', {
                method: 'POST',
                body: formData
            })
            .then(response => {
                if (!response.ok) {
                    throw new Error('Server returned an error: ' + response.status);
                }
                return response.json();
            })
            .then(data => {
                console.log('API response:', data);
                
                // Remove the temporary processing message
                conversationHistory.pop();
                
                // Update the conversation history with the real data
                conversationHistory = data.history;
                
                // Update the user name if provided
                if (data.user_name) {
                    userName = data.user_name;
                }
                
                // Update the message display
                updateMessageDisplay();
                
                // Save conversation to sessionStorage for the analysis page
                sessionStorage.setItem('currentConversation', JSON.stringify(conversationHistory));
                
                // Check if we have audio
                if (data.audio_base64 && data.status !== "partial_success") {
                    const audio = new Audio("data:audio/mp3;base64," + data.audio_base64);
                    audio.onended = function() {
                        statusText.textContent = "Ready for next turn";
                        // Reset for next recording
                        audioChunks = [];
                        // Automatically start recording for the next turn
                        setTimeout(() => {
                            startRecordingProcess();
                        }, 500);
                    };
                    audio.onerror = function(e) {
                        console.error("Audio playback failed:", e);
                        statusText.textContent = "Response received (audio failed)";
                        // Still continue with the conversation
                        setTimeout(() => {
                            startRecordingProcess();
                        }, 500);
                    };
                    audio.play().catch(e => {
                        console.error("Audio play error:", e);
                        statusText.textContent = "Response received (audio failed)";
                        // Still continue with the conversation
                        setTimeout(() => {
                            startRecordingProcess();
                        }, 500);
                    });
                    statusText.innerHTML = '<span class="indicator"></span> Playing response...';
                } else {
                    // No audio available, but we can still continue
                    statusText.textContent = "Response received (no audio)";
                    // Automatically start recording for the next turn
                    setTimeout(() => {
                        startRecordingProcess();
                    }, 500);
                }
            })
            .catch(error => {
                console.error('Error sending to server:', error);
                // Remove the temporary processing message
                conversationHistory.pop();
                updateMessageDisplay();
                statusText.textContent = "Error: " + error.message;
                // Try to start recording again
                setTimeout(() => {
                    startRecordingProcess();
                }, 500);
            });
        }

        // Initialize message display
        updateMessageDisplay();
    </script>
}
